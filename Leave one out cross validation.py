# -*- coding: utf-8 -*-
"""loocv2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dsGegiHC1NTfm3Gv-hEUkOBmf_UGESiN
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv('viscoo.csv')

# Separate features (X) and target variable (y)
X = df[['x1', 'x2']]
y = df['visc']

# Create empty arrays to store predicted and actual y values
y_pred = np.zeros(len(y))
y_actual = np.zeros(len(y))

# Initialize model
regr = RandomForestRegressor(n_estimators=3, max_depth=4, random_state=34)

# Leave-one-out cross-validation loop
for i in range(len(X)):
    # Get the index of the left-out sample
    left_out_index = i
    
    # Split the data into training set (all samples except left-out sample) and test set (left-out sample)
    X_train = X.drop(index=left_out_index)
    y_train = y.drop(index=left_out_index)
    X_test = X.loc[[left_out_index]]
    
    # Fit the model on training data and predict the left-out sample
    regr.fit(X_train, y_train)
    y_pred[i] = regr.predict(X_test)
    y_actual[i] = y.loc[left_out_index]

# Print mean square error and mean absolute error on training data
print("Mean square error train:", mean_squared_error(y, y_pred))
print("Mean absolute error train:", mean_absolute_error(y, y_pred))

# Print the predicted and actual values of y
print("Y Actual:", y_actual)
print("Y Predicted:", y_pred)